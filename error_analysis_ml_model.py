# -*- coding: utf-8 -*-
"""Error_Analysis_ML_Model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1aKQd5J0ldy4SnYWNdTgvm6n0CizAlIqQ
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

df_original = pd.read_csv('/content/drive/MyDrive/NiazSir_Research/Predict Ovarian Cancer_withlevel (2).csv')
df_original.head()

cols = df_original.columns.tolist()

from sklearn.feature_selection import mutual_info_classif
feature_df =df_original [['MPV','BASO#' ,'PHOS', 'GLU.', 'K','AST', 'BASO%','Mg','Menopause','CL','CEA','EO#','CA19-9','ALB','IBIL','GGT','MCH','GLO','ALT','DBIL','Age','RDW',
                          'PDW','CREA','AFP','HGB','Na','HE4','LYM#','CA125','BUN','LYM%','Ca','AG','MONO#','PLT','NEU','EO%','TP','UA','RBC','PCT','CO2CP','TBIL',
                          'HCT','MONO%','MCV','ALP']]
pk_class_labels =df_original['TYPE']

# importing libraries
import numpy as np
import sklearn
from sklearn import metrics
import pandas as pd
 
from sklearn.model_selection import train_test_split

stp_train_X, stp_test_X, stp_train_y, stp_test_y = train_test_split(feature_df, 
             pk_class_labels, test_size=0.3, random_state=42)

"""SVM LINEAR"""

from sklearn.svm import SVC
classifier2 = SVC(kernel="linear")
classifier2.fit(stp_train_X, stp_train_y)
y_pred_lin = classifier2.predict(stp_test_X)

mae_lr = round(metrics.mean_absolute_error(stp_test_y,y_pred_lin ), 4)
mse_lr = round(metrics.mean_squared_error(stp_test_y, y_pred_lin), 4)

compare_models = pd.DataFrame(
    {  
        'MAE'  : [mae_lr],
        'MSE'  : [mse_lr]
    })
print(compare_models)

"""SVM RBF"""

from sklearn.svm import SVC
classifier33 = SVC(kernel="rbf")
classifier33.fit(stp_train_X, stp_train_y)

y_svc = classifier33.predict(stp_test_X)

mae_lr = round(metrics.mean_absolute_error(stp_test_y,y_svc ), 4)
mse_lr = round(metrics.mean_squared_error(stp_test_y,y_svc ), 4)

compare_models = pd.DataFrame(
    {  
        'MAE'  : [mae_lr],
        'MSE'  : [mse_lr]
    })
print(compare_models)

"""KNN"""

#Fitting K-NN classifier to the training set  
from sklearn.neighbors import KNeighborsClassifier  
classifier= KNeighborsClassifier(n_neighbors=5, metric='minkowski', p=2 )  
classifier.fit(stp_train_X,stp_train_y )

k_pred = classifier.predict(stp_test_X)

mae_lr = round(metrics.mean_absolute_error(stp_test_y,k_pred ), 4)
mse_lr = round(metrics.mean_squared_error(stp_test_y,k_pred), 4)

compare_models = pd.DataFrame(
    {  
        'MAE'  : [mae_lr],
        'MSE'  : [mse_lr]
    })
print(compare_models)

"""LDA"""

from sklearn.discriminant_analysis import LinearDiscriminantAnalysis

classifier = LinearDiscriminantAnalysis()
classifier.fit(stp_train_X, stp_train_y)
pred_lda = classifier.predict(stp_test_X)

mae_lr = round(metrics.mean_absolute_error(stp_test_y,pred_lda ), 4)
mse_lr = round(metrics.mean_squared_error(stp_test_y,pred_lda), 4)

compare_models = pd.DataFrame(
    {  
        'MAE'  : [mae_lr],
        'MSE'  : [mse_lr]
    })
print(compare_models)

"""AdaBoost """

from sklearn.ensemble import AdaBoostClassifier
# Create adaboost classifer object
abc = AdaBoostClassifier(n_estimators=50,
                         learning_rate=1)

# Train Adaboost Classifer
model = abc.fit(stp_train_X, stp_train_y)

#Predict the response for test dataset
y_ada = model.predict(stp_test_X)

mae_lr1 = round(metrics.mean_absolute_error(stp_test_y,y_ada  ), 4)
mse_lr1 = round(metrics.mean_squared_error(stp_test_y,y_ada ), 4)

compare_models = pd.DataFrame(
    {  
        'MAE'  : [mae_lr1],
        'MSE'  : [mse_lr1]
    })
print(compare_models)

"""RandomForest"""

# importing random forest classifier from assemble module
from sklearn.ensemble import RandomForestClassifier
# Create a Random forest Classifier
clf2 = RandomForestClassifier(n_estimators = 100)
 
# Train the model using the training sets
clf2.fit(stp_train_X, stp_train_y)

y_pred_rn = clf2.predict(stp_test_X)

mae_lr2 = round(metrics.mean_absolute_error(stp_test_y,y_pred_rn  ), 4)
mse_lr2 = round(metrics.mean_squared_error(stp_test_y,y_pred_rn ), 4)

compare_models = pd.DataFrame(
    {  
        'MAE'  : [mae_lr2],
        'MSE'  : [mse_lr2]
    })
print(compare_models)

"""***K fold cross validation***

SVM LINEAR
"""

from sklearn import linear_model
from sklearn.model_selection import cross_val_score
from sklearn.svm import SVC

reg = SVC(kernel="linear")
scoring = 'neg_mean_absolute_error'
mae = cross_val_score(reg,feature_df ,pk_class_labels, cv=5,scoring=scoring)
print("Mean Absolute Error :{:.3f}".format(mae.mean()* -1))

"""SVM RBF"""

reg1 = SVC(kernel="rbf")
scoring = 'neg_mean_absolute_error'
mae = cross_val_score(reg1,feature_df ,pk_class_labels, cv=5,scoring=scoring)
print("Mean Absolute Error :{:.3f}".format(mae.mean()* -1))

"""KNN"""

from sklearn.neighbors import KNeighborsClassifier  
reg2= KNeighborsClassifier(n_neighbors=5, metric='minkowski', p=2 )  
scoring = 'neg_mean_absolute_error'
mae = cross_val_score(reg2,feature_df ,pk_class_labels, cv=5,scoring=scoring)
print("Mean Absolute Error :{:.3f}".format(mae.mean()* -1))

"""LDA"""

from sklearn.discriminant_analysis import LinearDiscriminantAnalysis

reg3 = LinearDiscriminantAnalysis()
scoring = 'neg_mean_absolute_error'
mae = cross_val_score(reg3,feature_df ,pk_class_labels, cv=5,scoring=scoring)
print("Mean Absolute Error :{:.3f}".format(mae.mean()* -1))

"""ADA BOOST"""

from sklearn.ensemble import AdaBoostClassifier
# Create adaboost classifer object
abc = AdaBoostClassifier(n_estimators=50,
                         learning_rate=1)

scoring = 'neg_mean_absolute_error'
mae = cross_val_score(abc,feature_df ,pk_class_labels, cv=5,scoring=scoring)
print("Mean Absolute Error :{:.3f}".format(mae.mean()* -1))

"""RANDOM FOREST"""

# importing random forest classifier from assemble module
from sklearn.ensemble import RandomForestClassifier
# Create a Random forest Classifier
clf2 = RandomForestClassifier(n_estimators = 100)

scoring = 'neg_mean_absolute_error'
mae = cross_val_score(clf2,feature_df ,pk_class_labels, cv=5,scoring=scoring)
print("Mean Absolute Error :{:.3f}".format(mae.mean()* -1))

"""NESTED K FOLD VALIDATION"""

from sklearn.svm import SVC
from sklearn.model_selection import cross_val_score,StratifiedKFold
import pandas as pd # for data manipulation
import numpy as np # for data manipulation

from sklearn.model_selection import train_test_split # for splitting the data into train and test samples
from sklearn.metrics import classification_report # for model evaluation metrics
from sklearn.svm import SVC # for Support Vector Classification model

from sklearn.model_selection import cross_val_score,StratifiedKFold
from sklearn.model_selection import LeaveOneOut
from sklearn.model_selection import TimeSeriesSplit
from sklearn.model_selection import LeavePGroupsOut
from sklearn.model_selection import RepeatedKFold

import plotly.express as px  # for data visualization
import plotly.graph_objects as go

#SVM LINNEAR
clf33 = SVC(kernel="linear", probability=True)
stratifiedkf=RepeatedKFold(n_splits=5, n_repeats=5, random_state=42)
scoring = 'neg_mean_absolute_error'
mae = cross_val_score(clf33,feature_df ,pk_class_labels, cv=stratifiedkf,scoring=scoring)
print("SVM LINEAR Mean Absolute  Error :{:.3f}".format(mae.mean()* -1))

#SVM RBF
clf34 = SVC(kernel="rbf", probability=True)
stratifiedkf=RepeatedKFold(n_splits=5, n_repeats=5, random_state=42)
scoring = 'neg_mean_absolute_error'
mae1 = cross_val_score(clf34,feature_df ,pk_class_labels, cv=stratifiedkf,scoring=scoring)
print("SVM rbf Mean Absolute  Error :{:.3f}".format(mae1.mean()* -1))

#KNN
from sklearn.neighbors import KNeighborsClassifier  
reg2= KNeighborsClassifier(n_neighbors=5, metric='minkowski', p=2 ) 
stratifiedkf=RepeatedKFold(n_splits=5, n_repeats=5, random_state=42) 
scoring = 'neg_mean_absolute_error'
mae = cross_val_score(reg2,feature_df ,pk_class_labels, cv=stratifiedkf,scoring=scoring)
print(" KNN Mean Absolute Error :{:.3f}".format(mae.mean()* -1))

#LDA
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
classifier22 = LinearDiscriminantAnalysis()
stratifiedkf=RepeatedKFold(n_splits=5, n_repeats=5, random_state=42)
scoring = 'neg_mean_absolute_error'
mae3 = cross_val_score(classifier22,feature_df ,pk_class_labels, cv=stratifiedkf,scoring=scoring)
print(" LDA Mean Absolute Error :{:.3f}".format(mae3.mean()* -1))

#ADA BOOST
from sklearn.model_selection import cross_val_score,StratifiedKFold
from sklearn.ensemble import AdaBoostClassifier
classifier23 = AdaBoostClassifier(n_estimators=100, learning_rate=1)
stratifiedkf=RepeatedKFold(n_splits=5, n_repeats=5, random_state=42)
scoring = 'neg_mean_absolute_error'
mae3 = cross_val_score(classifier23,feature_df ,pk_class_labels, cv=stratifiedkf,scoring=scoring)
print(" ADA BOOST Mean Absolute Error :{:.3f}".format(mae3.mean()* -1))

#RANDOM FOREST
# importing random forest classifier from assemble module
from sklearn.ensemble import RandomForestClassifier
# Create a Random forest Classifier
classifier66 = RandomForestClassifier(n_estimators = 100)
stratifiedkf11=RepeatedKFold(n_splits=5, n_repeats=5, random_state=42)
scoring = 'neg_mean_absolute_error'
mae3 = cross_val_score(classifier66,feature_df ,pk_class_labels, cv=stratifiedkf11,scoring=scoring)
print("Random forest Mean Absolute Error :{:.3f}".format(mae3.mean()* -1))

"""MONTECARLO VALIDATION"""

from sklearn.model_selection import cross_val_score,StratifiedKFold
from sklearn.model_selection import ShuffleSplit,cross_val_score
from sklearn.svm import SVC
from sklearn import datasets

#SVM Linear 
from sklearn.svm import SVC
from sklearn.model_selection import ShuffleSplit,cross_val_score
from sklearn.svm import SVC
classifier2 = SVC(kernel="linear")
shuffle_split=ShuffleSplit(test_size=0.3,train_size=0.5,n_splits=5)
scoring = 'neg_mean_absolute_error'
mae3 = cross_val_score(classifier2,feature_df ,pk_class_labels, cv=shuffle_split,scoring=scoring)
print("SVM RBF Mean Absolute Error :{:.3f}".format(mae3.mean()* -1))

#SVM RBF
classifier2 = SVC(kernel="rbf")
shuffle_split=ShuffleSplit(test_size=0.3,train_size=0.5,n_splits=5)
scoring = 'neg_mean_absolute_error'
mae4 = cross_val_score(classifier2,feature_df ,pk_class_labels, cv=shuffle_split,scoring=scoring)
print("SVM RBF Mean Absolute Error :{:.3f}".format(mae4.mean()* -1))

#KNN
from sklearn.neighbors import KNeighborsClassifier  
reg2= KNeighborsClassifier(n_neighbors=5, metric='minkowski', p=2)
shuffle_split=ShuffleSplit(test_size=0.3,train_size=0.5,n_splits=5)
scoring = 'neg_mean_absolute_error'
mae4 = cross_val_score(reg2,feature_df ,pk_class_labels, cv=shuffle_split,scoring=scoring)
print("KNN Mean Absolute Error :{:.3f}".format(mae4.mean()* -1))

#LDA
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
reg3 = LinearDiscriminantAnalysis()
shuffle_split=ShuffleSplit(test_size=0.3,train_size=0.5,n_splits=5)
scoring = 'neg_mean_absolute_error'
mae5 = cross_val_score(reg3,feature_df ,pk_class_labels, cv=shuffle_split,scoring=scoring)
print("LDA Mean Absolute Error :{:.3f}".format(mae5.mean()* -1))

#ADA BOOST
from sklearn.model_selection import cross_val_score,StratifiedKFold
from sklearn.ensemble import AdaBoostClassifier
classifier23 = AdaBoostClassifier(n_estimators=100, learning_rate=1)
shuffle_split=ShuffleSplit(test_size=0.3,train_size=0.5,n_splits=5)
scoring = 'neg_mean_absolute_error'
mae5 = cross_val_score(classifier23 ,feature_df ,pk_class_labels, cv=shuffle_split,scoring=scoring)
print("ADA BOOST Mean Absolute Error :{:.3f}".format(mae5.mean()* -1))

#RANDOM FOREST
# importing random forest classifier from assemble module
from sklearn.ensemble import RandomForestClassifier
# Create a Random forest Classifier
classifier66 = RandomForestClassifier(n_estimators = 100)
shuffle_split=ShuffleSplit(test_size=0.3,train_size=0.5,n_splits=5)
scoring = 'neg_mean_absolute_error'
mae6 = cross_val_score(classifier66 ,feature_df ,pk_class_labels, cv=shuffle_split,scoring=scoring)
print("RANDOM FOREST Mean Absolute Error :{:.3f}".format(mae6.mean()* -1))